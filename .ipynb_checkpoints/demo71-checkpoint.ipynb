{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d82b708-a16c-4f08-bdfc-c8c8f78937bf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
      " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215687\n",
      " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
      " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
      " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313726\n",
      " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.13725491 0.94509804\n",
      " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
      " 0.5882353  0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
      " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.5803922\n",
      " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058825\n",
      " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
      " 0.3137255  0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333336 0.99215686\n",
      " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 199,210\n",
      "Trainable params: 199,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3608 - accuracy: 0.8926\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0978 - accuracy: 0.9719\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0663 - accuracy: 0.9817\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0514 - accuracy: 0.9854\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0445 - accuracy: 0.9872\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0390 - accuracy: 0.9892\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0332 - accuracy: 0.9909\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0290 - accuracy: 0.9917\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0290 - accuracy: 0.9930\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0233 - accuracy: 0.9945\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0206 - accuracy: 0.9953\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0212 - accuracy: 0.9954\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0204 - accuracy: 0.9951\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0130 - accuracy: 0.9964\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0160 - accuracy: 0.9966\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0119 - accuracy: 0.9969\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0145 - accuracy: 0.9966\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0142 - accuracy: 0.9967\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0110 - accuracy: 0.9972\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0091 - accuracy: 0.9977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24e2ca88748>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.shape)\n",
    "FLATTEN_DIM = 28 * 28\n",
    "TRAINING_SIZE = len(train_images)\n",
    "TEST_SIZE = len(test_images)\n",
    "\n",
    "trainImages = np.reshape(train_images, (TRAINING_SIZE, FLATTEN_DIM))\n",
    "testImages = np.reshape(test_images, (TEST_SIZE, FLATTEN_DIM))\n",
    "print(trainImages[0])\n",
    "\n",
    "trainImages = trainImages.astype(np.float32)\n",
    "testImages = testImages.astype(np.float32)\n",
    "trainImages /= 255\n",
    "testImages /= 255\n",
    "print(trainImages[0])\n",
    "\n",
    "NUM_DIGITS = 10\n",
    "trainLabels = to_categorical(train_labels, NUM_DIGITS)\n",
    "testLabels = to_categorical(test_labels, NUM_DIGITS)\n",
    "print(trainLabels[0])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=200, activation=tf.nn.relu, input_shape=(FLATTEN_DIM,)))\n",
    "model.add(Dense(units=200, activation=tf.nn.relu))\n",
    "model.add(Dense(units=10, activation=tf.nn.softmax))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "tbCallback = TensorBoard(log_dir=\"./logs/demo70\", histogram_freq=0,\n",
    "                         write_graph=True, write_images=True)\n",
    "model.fit(trainImages, trainLabels, epochs=20, callbacks=[tbCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b00babf-d0c8-4c73-9939-d199ea75b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\envs\\tf_ml_ds_37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 6, 9], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedLabels = model.predict_classes(testImages)\n",
    "predictedLabels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3216321e-2c1a-461c-969f-7c13bc8880fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 6.8399163e-37, 3.4492959e-31,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "        0.0000000e+00, 6.6664779e-36],\n",
       "       [0.0000000e+00, 7.9685257e-32, 1.0000000e+00, 1.0345621e-36,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [1.0951068e-28, 1.0000000e+00, 5.6673558e-14, 7.2018520e-23,\n",
       "        9.4184489e-18, 3.3438065e-18, 8.8033358e-19, 3.2190080e-11,\n",
       "        3.3286194e-13, 7.8764542e-21],\n",
       "       [1.0000000e+00, 2.8332035e-31, 2.1558304e-17, 1.7480078e-20,\n",
       "        2.1770037e-24, 4.6300909e-17, 6.2237174e-11, 9.5119702e-17,\n",
       "        3.2011166e-19, 5.4352551e-13],\n",
       "       [3.0865724e-35, 0.0000000e+00, 1.2860745e-30, 1.1462960e-37,\n",
       "        1.0000000e+00, 5.3566940e-33, 3.6766583e-33, 4.0594944e-22,\n",
       "        1.3808324e-35, 1.5402090e-17],\n",
       "       [4.0806379e-31, 1.0000000e+00, 2.0557005e-20, 2.6499061e-25,\n",
       "        1.7212123e-13, 1.4685108e-26, 1.9515772e-27, 8.8986986e-12,\n",
       "        1.1167552e-16, 1.6762529e-20],\n",
       "       [0.0000000e+00, 7.6871218e-31, 0.0000000e+00, 2.5102738e-36,\n",
       "        1.0000000e+00, 8.8092483e-34, 0.0000000e+00, 2.1084533e-26,\n",
       "        2.0455641e-26, 1.8013984e-20],\n",
       "       [8.4417022e-27, 5.8958997e-31, 2.0621139e-12, 4.5532452e-08,\n",
       "        6.5053309e-14, 1.6644203e-09, 1.9570478e-36, 8.5082484e-13,\n",
       "        7.6914256e-18, 1.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        5.1957155e-28, 1.1582918e-04, 9.9988413e-01, 0.0000000e+00,\n",
       "        2.3037268e-38, 2.3841451e-32],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        2.7812082e-13, 0.0000000e+00, 0.0000000e+00, 2.9573695e-24,\n",
       "        9.2317806e-31, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model.predict(testImages)\n",
    "predicted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07272bd-7773-48a0-9c9f-dc2696bf8a8f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\envs\\tf_ml_ds_37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 6.8399163e-37, 3.4492959e-31,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "        0.0000000e+00, 6.6664779e-36],\n",
       "       [0.0000000e+00, 7.9685257e-32, 1.0000000e+00, 1.0345621e-36,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [1.0951068e-28, 1.0000000e+00, 5.6673558e-14, 7.2018520e-23,\n",
       "        9.4184489e-18, 3.3438065e-18, 8.8033358e-19, 3.2190080e-11,\n",
       "        3.3286194e-13, 7.8764542e-21],\n",
       "       [1.0000000e+00, 2.8332035e-31, 2.1558304e-17, 1.7480078e-20,\n",
       "        2.1770037e-24, 4.6300909e-17, 6.2237174e-11, 9.5119702e-17,\n",
       "        3.2011166e-19, 5.4352551e-13],\n",
       "       [3.0865724e-35, 0.0000000e+00, 1.2860745e-30, 1.1462960e-37,\n",
       "        1.0000000e+00, 5.3566940e-33, 3.6766583e-33, 4.0594944e-22,\n",
       "        1.3808324e-35, 1.5402090e-17],\n",
       "       [4.0806379e-31, 1.0000000e+00, 2.0557005e-20, 2.6499061e-25,\n",
       "        1.7212123e-13, 1.4685108e-26, 1.9515772e-27, 8.8986986e-12,\n",
       "        1.1167552e-16, 1.6762529e-20],\n",
       "       [0.0000000e+00, 7.6871218e-31, 0.0000000e+00, 2.5102738e-36,\n",
       "        1.0000000e+00, 8.8092483e-34, 0.0000000e+00, 2.1084533e-26,\n",
       "        2.0455641e-26, 1.8013984e-20],\n",
       "       [8.4417022e-27, 5.8958997e-31, 2.0621139e-12, 4.5532452e-08,\n",
       "        6.5053309e-14, 1.6644203e-09, 1.9570478e-36, 8.5082484e-13,\n",
       "        7.6914256e-18, 1.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        5.1957155e-28, 1.1582918e-04, 9.9988413e-01, 0.0000000e+00,\n",
       "        2.3037268e-38, 2.3841451e-32],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        2.7812082e-13, 0.0000000e+00, 0.0000000e+00, 2.9573695e-24,\n",
       "        9.2317806e-31, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_prob = model.predict_proba(testImages)\n",
    "predicted_prob[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28017020-c9e8-4e13-bf68-923342413c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plotTestImage(index):\n",
    "    plt.title(\"test image marked as %d, predict as %d\"%(test_labels[index],predictedLabels[index]))\n",
    "    plt.imshow(test_images[index],cmap='binary')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abafd08b-45f0-414c-915d-76ff8d591687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'c:\\\\users\\\\admin\\\\envs\\\\tf_ml_ds_37\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEICAYAAAB/KknhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT1ElEQVR4nO3dfZBddX3H8fcnDxRMUILZSWNAgoog+EBkGx2lEEWUUJwANSCtEio2tAMWWi0ibTXtWIdhVBRrtbFCIgjKqKkgUKWpIJTosEBI0MiDuIGEkCwmSAKohHz7x/mtnCx77u7e5+T3ec3c2XvP7zx877m/zz0P9949igjMLC/jOl2AmbWfg2+WIQffLEMOvlmGHHyzDDn4Zhna7YIv6UZJCzpdR6dJCkmvasJ8bpb0wWbUtCuStEjSlen+yyVtkzS+03U1qi3Bl9Qv6R1NmM8Zkm6rNU5EzI2IpY0uy9pH0imSbpf0tKSbO11PlYh4OCImR8RztcaTNEfSunbUJOkcSX2SfitpyWinm9DCmqwDJE2IiO2drmOMNgOfAw4B3t6qheyi62YkjwKfBN4F7DXqqSKipTfgCmAH8AywDTg/DX8zcDvwBHAPMKc0zRnAQ8BW4JfAnwOvAX4DPJfm80TF8m4GPliaz/8Bl6TlPAS8JQ1/BNgELChN+yfA3cCTqX3RkHmfDqwFfgX8E9APvCO1jQMuAH6R2q8B9q2ocQ6wDjg/1bABOBE4HrifIggXlsafDaxIz2ED8G/AHqX2AM4GHgB+WRr2qnT/yPR85qTHHwDWAFuA7wMHlOZ1LPBz4NdpObcMrs9hnkdlXYDSet+U1udq4LUj9JUPAjePsX8tAr4FfDP1l7uAN5Ta+4GPAquA31Js7Gr1vQPTc94K3JSe05WpbWZarxPS432ByynCtwX4L2ASRV/fQdFPtwEvG6buyr4G7AlcmfrRE8AdwLQR1sMngSWjXm+tDn5p5b+j9HhGelLHUwTm2PS4J624J4GD07jTgcNKQb5thGXdzM7B3w78BTA+rZyHgS8CfwC8M73Ak0uBfF2q6fXARuDE1HZoehGPBPYAPg08y/PBPxf4MbBfmvd/AFfXCP524OPAROAvgQHgKmBv4LDUeQ5M4x+ROuuE1PnWAOcNCf5NqSPuVQ4+cFzqWLPT8HnAgxRvpBOAfwRuT21T0/p4T6rrb1OdVcGvrItiC3QnsA/Fm8BrgOktCv6zpZo/QrGxmFjqeyuB/Sm2iJV9L42/Avhseg2PSuujKvjXU7zhTEnLPrr0+q4boe45VPe1s4DrgBdR9NsjgBfvDsH/KHDFkHG+DyygCP4TwJ8OduLSOGcw9uA/UGp7XXrhppWG/Qo4vGJenwMuSfc/TinI6UX5Hc8Hfw1wTKl9euqQEype9GeA8enx3qmuN5XGuXOwIwwz/XnAstLjAN4+ZJwAPkaxh/La0vAbgTNLj8cBTwMHUOzR/LjUJoo9k2GDX6suil32+yneGMaNcvp6g1+ueRzF3scfl/reB0bZ915O8UY3qdR2FcMEP72+O4ApFa9vzeCP0Nc+QLFH8voxTD+m4HfqrP4BwHxJTwzeKLak0yPiKeBU4K+ADZKul3RIA8vaWLr/DEBEDB02GUDSmyT9UNKApF+nGqam8V5GseUkzeNpijeN8nNaVno+aygOS6ZV1PWreP4k0TMVtQ7W9WpJ35P0mKQngU+V6hr0CC90HnBNRNw7pM7Pl+rcTBHwGcM8x6iYLyPVFRH/S7Gb/EVgk6TFkl5cNa8GlWveQfFm9bLh2qnR99I0W1IfHLS2Ypn7A5sjYks9BY/Q166geDP6hqRHJV0saWI9y6nSruAP/QngIxTvuvuUbpMi4iKAiPh+RBxL8WL8HPhKxXya7SrgWmD/iHgJ8GWKUECxFdlvcERJewEvLU37CDB3yHPaMyLWN6GuL1Gsh4Mi4sXAhaW6Bg23buYDJ0o6d0idZw2pc6+IuJ3iOe4/OKIklR+Pta6IuDQijqA4THo18Peje7pjVq55HMXr9GipvbxuavW9DcAUSZNK47+8YpmPAPtK2meYttH008q+FhHPRsQ/R8ShFOekTqDYG2uadgV/I/CK0uMrgXdLepek8ZL2TB+B7CdpmqR5aeX/luK4ekdpPvtJ2qNFde5N8S7+G0mzgT8rtX0r1fyWtPxF7By+LwP/KukAAEk9kuY1sa4ngW1p7+evRzndo8AxwLmSBqf5MvAxSYelOl8iaX5qux44TNLJkiYAfwP8YT11SfqjtFWbCDxFcWJ2x3AzGewDFLvQ41J/mFhq75d0Ro06jijVfB5Fv/lxxbiVfS8i1gJ9wD9L2kPSkcC7h5tJRGygOGz6d0lTJE2UdFRq3gi8VNJLatRc2dckvU3S69L3BZ6kOGSsWncT0robDww+n5E/rRvLcUi9N4oTSg9THLt/JA17E8XZ080UJ7aup3h3nZ6G/zqNfzNwaJpmjzTeZuDximXdzM7H+LeV2l5F2oMtDVsHHJnuv4di124r8D1KZ3RL83uY58/qr+f5Y8lxwN8B96XpfwF8qqLGOZSOASk6fAAzS8NuA96X7h9FsWXdBtwK/MuQ5xWkM/jDDaM4U722tF7eT3GWffCM8mWl6Y6jODYfzVn9yroo3nBWpbbHga+TTqIOM58zUr3l25LSa74VOKRi2kXsfFb/buCNpfZ+SueXavW91PaK9Fy2Mbqz+kspgr4F+E5pGZfx/Fn54c7qV/Y14LTUj55K876UYc4VlZ7/0HW3aKRMKk1sYyRpMsWLelBE/LLD5ey20lb37Ig4raJ9EcUb3PvaWtgubrf7ym4rSXq3pBelw5BPU2w1+ztb1e4tIm6rCr3Vz8Efm3kUx82PAgcB7w3vMtkuyLv6ZhnyFt8sQ239kc7UqVNj5syZ7VykWVb6+/t5/PHHh37H4wUaCr6k44DPU3yG+J/pSxCVZs6cSV9fXyOLNLMaent7RzVe3bv66csFXwTmUnwz6zRJh9Y7PzNrn0aO8WcDD0bEQxHxO+AbFGe9zazLNRL8Gez844d1adhOJC1M/yGkb2BgoIHFmVmztPysfkQsjojeiOjt6elp9eLMbBQaCf56dv7l1n5pmJl1uUaCfwdwkKQD06/V3kvxM0Mz63J1f5wXEdslnUPxDwPGU/zC66dNq8zMWqahz/Ej4gbghibVYmZt4q/smmXIwTfLkINvliEH3yxDDr5Zhhx8sww5+GYZcvDNMuTgm2XIwTfLkINvliEH3yxDDr5Zhhx8sww5+GYZcvDNMuTgm2XIwTfLkINvliEH3yxDDr5Zhtp6mWzLz/3331/ZdvDBB9ec9tJLL63Z/qEPfaiumsxbfLMsOfhmGXLwzTLk4JtlyME3y5CDb5YhB98sQ/4c31rq7rvvrmwbN672dmfGjBnNLseShoIvqR/YCjwHbI+I3mYUZWat1Ywt/tsi4vEmzMfM2sTH+GYZajT4AfxA0p2SFg43gqSFkvok9Q0MDDS4ODNrhkaDf2REvBGYC5wt6aihI0TE4ojojYjenp6eBhdnZs3QUPAjYn36uwlYBsxuRlFm1lp1B1/SJEl7D94H3gnc26zCzKx1GjmrPw1YJmlwPldFxH83pSrbbaxcubKybfLkyTWnPfnkk5tcjQ2qO/gR8RDwhibWYmZt4o/zzDLk4JtlyME3y5CDb5YhB98sQ/5ZrjVk9erVNdu/8IUvVLadfvrpzS7HRslbfLMMOfhmGXLwzTLk4JtlyME3y5CDb5YhB98sQ/4c3xpy33331Wx/6qmnKttOPfXUZpdjo+QtvlmGHHyzDDn4Zhly8M0y5OCbZcjBN8uQg2+WIX+Obw25+OKLa7bPnDmzsq231xdX7hRv8c0y5OCbZcjBN8uQg2+WIQffLEMOvlmGHHyzDPlzfKupv7+/Zvsdd9xRs/3ggw+ubJs0aVI9JVkTjLjFl3SZpE2S7i0N21fSTZIeSH+ntLZMM2um0ezqLwGOGzLsAmB5RBwELE+PzWwXMWLwI+JHwOYhg+cBS9P9pcCJzS3LzFqp3pN70yJiQ7r/GDCtakRJCyX1SeobGBioc3Fm1kwNn9WPiACiRvviiOiNiN6enp5GF2dmTVBv8DdKmg6Q/m5qXklm1mr1Bv9aYEG6vwD4bnPKMbN2GPFzfElXA3OAqZLWAZ8ALgKukXQmsBY4pZVFWufccsstDU3vw7vuNGLwI+K0iqZjmlyLmbWJv7JrliEH3yxDDr5Zhhx8sww5+GYZ8s9yraZVq1Y1NP3555/fpEqsmbzFN8uQg2+WIQffLEMOvlmGHHyzDDn4Zhly8M0y5M/xM7dixYqa7ZdffnnN9lmzZtVsP/bYY8dck7Wet/hmGXLwzTLk4JtlyME3y5CDb5YhB98sQw6+WYb8OX7mli9fXrN9y5YtNduPO27o9VR3tueee465Jms9b/HNMuTgm2XIwTfLkINvliEH3yxDDr5Zhhx8swz5c/zM3XPPPQ1NP3/+/CZVYu004hZf0mWSNkm6tzRskaT1klam2/GtLdPMmmk0u/pLgOG+nnVJRByebjc0tywza6URgx8RPwI2t6EWM2uTRk7unSNpVToUmFI1kqSFkvok9Q0MDDSwODNrlnqD/yXglcDhwAbgM1UjRsTiiOiNiN6enp46F2dmzVRX8CNiY0Q8FxE7gK8As5tblpm1Ul3BlzS99PAk4N6qcc2s+4z4Ob6kq4E5wFRJ64BPAHMkHQ4E0A+c1boSrRGPPfZYzfZbb721ZvshhxxSs/2kk04ac03WeSMGPyJOG2bwV1tQi5m1ib+ya5YhB98sQw6+WYYcfLMMOfhmGfLPcndzS5Ysqdm+cePGmu1z585tYjXWLbzFN8uQg2+WIQffLEMOvlmGHHyzDDn4Zhly8M0y5M/xd3Nr165taPopUyr/q5rtwrzFN8uQg2+WIQffLEMOvlmGHHyzDDn4Zhly8M0y5M/xd3PXXXddQ9OfcMIJTarEuom3+GYZcvDNMuTgm2XIwTfLkINvliEH3yxDDr5ZhkZzmez9ga8B0ygui704Ij4vaV/gm8BMiktlnxIRW1pXqlWpdanrkf5vvuVpNFv87cCHI+JQ4M3A2ZIOBS4AlkfEQcDy9NjMdgEjBj8iNkTEXen+VmANMAOYByxNoy0FTmxRjWbWZGM6xpc0E5gF/ASYFhEbUtNjFIcCZrYLGHXwJU0Gvg2cFxFPltsiIiiO/4ebbqGkPkl9AwMDDRVrZs0xquBLmkgR+q9HxHfS4I2Spqf26cCm4aaNiMUR0RsRvT09Pc2o2cwaNGLwJQn4KrAmIj5baroWWJDuLwC+2/zyzKwVRvOz3LcC7wdWS1qZhl0IXARcI+lMYC1wSksqtBEtW7assm379u01p501a1bN9qOPPrqumqy7jRj8iLgNUEXzMc0tx8zawd/cM8uQg2+WIQffLEMOvlmGHHyzDDn4Zhnyv9feBTz99NM122+88ca65z1//vya7ePHj6973ta9vMU3y5CDb5YhB98sQw6+WYYcfLMMOfhmGXLwzTLkz/F3ARMnTqzZvs8++1S2zZs3r+a05557bj0l2S7OW3yzDDn4Zhly8M0y5OCbZcjBN8uQg2+WIQffLEP+HH8XMNLn+CtWrGhTJba78BbfLEMOvlmGHHyzDDn4Zhly8M0y5OCbZcjBN8vQiMGXtL+kH0r6maSfSjo3DV8kab2klel2fOvLNbNmGM0XeLYDH46IuyTtDdwp6abUdklEfLp15ZlZK4wY/IjYAGxI97dKWgPMaHVhZtY6YzrGlzQTmAX8JA06R9IqSZdJmlIxzUJJfZL6BgYGGqvWzJpi1MGXNBn4NnBeRDwJfAl4JXA4xR7BZ4abLiIWR0RvRPT29PQ0XrGZNWxUwZc0kSL0X4+I7wBExMaIeC4idgBfAWa3rkwza6bRnNUX8FVgTUR8tjR8emm0k4B7m1+embXCaM7qvxV4P7Ba0so07ELgNEmHAwH0A2e1oD4za4HRnNW/DdAwTTc0vxwzawd/c88sQw6+WYYcfLMMOfhmGXLwzTLk4JtlyME3y5CDb5YhB98sQw6+WYYcfLMMOfhmGXLwzTLk4JtlSBHRvoVJA8Da0qCpwONtK2BsurW2bq0LXFu9mlnbAREx4v+4a2vwX7BwqS8iejtWQA3dWlu31gWurV6dqM27+mYZcvDNMtTp4C/u8PJr6dbaurUucG31anttHT3GN7PO6PQW38w6wME3y1BHgi/pOEn3SXpQ0gWdqKGKpH5Jq9Olv/s6XMtlkjZJurc0bF9JN0l6IP0d9pqFHaqtKy6dXuPS7h1dd910yfm2H+NLGg/cDxwLrAPuAE6LiJ+1tZAKkvqB3ojo+Jc9JB0FbAO+FhGvTcMuBjZHxEXpTXNKRHy0S2pbBGzr9KXT01Weppcv7Q6cCJxBB9ddjbpOoc3rrRNb/NnAgxHxUET8DvgGMK8DdXS9iPgRsHnI4HnA0nR/KUXHabuK2rpCRGyIiLvS/a3A4KXdO7ruatTVdp0I/gzgkdLjdXToyVcI4AeS7pS0sNPFDGNaRGxI9x8DpnWymGGMeOn0dhpyafeuWXf1XHK+mXxy74WOjIg3AnOBs9MubVeK4jitmz6PHdWl09tlmEu7/14n1129l5xvpk4Efz2wf+nxfmlYV4iI9envJmAZ3Xf5742DVypOfzd1uJ7f66ZLpw93aXe6YN11yyXnOxH8O4CDJB0oaQ/gvcC1HajjBSRNSiddkDQJeCfdd/nva4EF6f4C4LsdrGUn3XLp9KpLu9PhdddVl5yPiLbfgOMpzuz/AviHTtRQUdcrgHvS7aedrg24mmLX71mKcyFnAi8FlgMPAP8D7NtFtV0BrAZWUYRseodqO5JiN34VsDLdju/0uqtRV9vXm7+ya5Yhn9wzy5CDb5YhB98sQw6+WYYcfLMMOfhmGXLwzTL0/woFys6vintRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotTestImage(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52098d06-5014-4a22-8bf1-8e0d13d2f2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predict</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>969</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1121</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1016</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>986</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>965</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>873</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>934</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>942</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predict    0     1     2    3    4    5    6     7    8    9\n",
       "label                                                       \n",
       "0        969     1     1    0    2    3    2     1    0    1\n",
       "1          0  1121     4    2    0    2    2     2    2    0\n",
       "2          0     2  1016    4    3    1    1     4    1    0\n",
       "3          0     0     4  986    0    6    0     4    0   10\n",
       "4          1     0     2    0  965    0    3     4    0    7\n",
       "5          2     0     0    7    1  873    3     0    2    4\n",
       "6          2     2     1    1    6   10  934     0    1    1\n",
       "7          0     0    14    2    0    0    0  1004    1    7\n",
       "8          2     1     2    6    4    5    1     4  942    7\n",
       "9          0     2     0    0    9    4    1     1    1  991"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.crosstab(test_labels, predictedLabels, rownames=['label'], colnames=['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb023c-5d94-44e3-953a-a73be9975f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
